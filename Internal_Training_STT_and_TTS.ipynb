{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Recognition : Google Speech To Text - Text To Speech API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Internal Training Algoritma**\n",
    "\n",
    "**Fafilia Masrofin**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biometrics is one of method or a way to recognize humans based on one or more physical characteristics or unique behavior. One of the biometrics that can be used is voice through speech recognition. Voice or widely we call speech is the most natural form of communication for humans.\n",
    "\n",
    "Speech Recognition is a system used to recognize word commands from human voices and then translate them into data that is understood by computers. Input in the form of sound that is captured by an audio device that will be translated / converted from an acoustic signal into an output in the form of text. At this time, this system is used to replace the input role of the keyboard or mouse. Words that are captured and recognized can be the end result for an application such as command & control, data input, and document preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Idea of  Speech Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Communication between humans will not occur without a word. When speaking we do speech synthesis, speech recognition, and speech understanding. When we talk about speech, we cannot mention that the context of a speech is simple. In a speech, the important context that occurs is where we speak, why we speak, who our audience is, and what our goals are  important. The way of humans speak is very varied. In short, a speech is very complex and complicated. In a speech, humans try to convey their thoughts and experiences through sound and language so that it can be understood by other humans. Communication through a greeting can be formulated and described as follows:\n",
    "\n",
    "1. The speaker formulates his words in a word\n",
    "2. The speaker produces sound from the vocal cords and speech system\n",
    "3. Sound is transmitted through acoustic waves in the air to the listener's ears as vibrations\n",
    "4. Sound is transmitted to the listener's brain through the auditory nerve\n",
    "5. The vibrations are converted into \"language\" in the listener's brain.\n",
    "6. The brain understands / extracts the meaning of the sound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](assets/communicate.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of Automation Speech Recognition (ASR) is build a system that can simulate how to hear humans, they can understand the spoken language and respond in other words that the system can react appropriately to the words spoken and convert the speech to other media like text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Speech Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the ability to recognize spoken words, there are 5 types of words identification, namely:\n",
    "- Isolated Words:\n",
    "The process of identifying words that can only recognize words that are spoken if the word has a pause of pronunciation between words\n",
    "- Connected Words:\n",
    "The process of identifying words is similar to isolated words, but requires a shorter time interval between words\n",
    "- Continuous Speech:\n",
    "The process of identifying words is more advanced because it can recognize words that are spoken continuously with very little time lag or without time lag. This speech recognition process is very complicated because it requires a special method to distinguish words that are spoken without time lag. Users of this device can say words naturally\n",
    "- Spontaneous Speech:\n",
    "The process of identifying words that can recognize words spoken spontaneously without time lag between words\n",
    "- Voice Verification / Identification:\n",
    "The process of identifying words is not only able to recognize words, but also identifies who is speaking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voice recognition or speech process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Main Scheme of Speech Recognition Scheme\n",
    "\n",
    "    The main components in a speech recognition system:\n",
    "    - Receiving input data: When we talk, we produce vibrations in the air. These vibrations form a signal which called an analog signal. The voice when we said then received by the input device in the form of a microphone. This microphone then captures the analog signal and then passes it through the electrical signal and converts it to a digital signal that can be read by a computer. To be able to convert signals from analog to digital, a converter called an Analog to Digital Converter (ADC) is needed. ADC will take a sample of our sound in the form of sound waves measuring precisely and periodically.\n",
    "    - Feature extraction (feature extraction): process of identifying parts of input that contains the utterance and then changing that parts into a sequence or what is known as an acoustic parameter.\n",
    "    - Data / corpus for training and testing: This database is a collection of recorded utterances. This corpus must be large enough and relevant enough to cover diversity of speech.\n",
    "    - Acoustic modeling: Acoustic models take the form of speech waves and break them into small fragments and predict the phonemes most likely in a speech.\n",
    "    - Modeling the pronunciation: The pronunciation model emits sounds and binds them together to form words (associating words with their phonetic representations)\n",
    "    - Language modeling: Language models take words and tie them together to form sentences, i.e. predict the most likely word order (or text strings) among several sets of text strings.\n",
    "    - Decoder: combines acoustic and language model predictions and produces text strings that are most likely to input a given speech file\n",
    "\n",
    "2. Block Speech Recognition Stage with HMM\n",
    "\n",
    "    - Feature extraction stage: Filtering sound signals and converting analog to digital sound signals. Feature extraction is used in the training and introduction phase. The main purpose of Feature Extraction is to simplify recognition by summarizing large amounts of speech data without losing the acoustic properties that define the speech. Feature extraction consists of the following steps:\n",
    "        - Frame Blocking: An investigation shows that the characteristics of speech signals remain stationary for a fairly short period of time (quasi-stationary). For this reason, speech signals are processed in short time intervals and divided into frames with generally sizes between 30 and 100 milliseconds. Each frame overlaps by the previous frame with the specified size. The purpose of the overlapping scheme is to smooth the transition from frame to frame.\n",
    "        - Windowing: The second step is windowing. This is done to eliminate discontinuity at the edges of the frame. If the windowing function is defined as *w (n)*, *0 <n <N-1* where *N* is the number of samples in each frame, the resulting signal is *y (n) = x (n) w (n)*. A common method that is often used is Hamming Windows.\n",
    "        - FFT (Fast Fourier Transform): The next step is to take Fast Fourier Transform from each frame. This transformation changes the domain from time to frequency.\n",
    "        - Mel-Frequency Wrapping: Signals for each frame are passed through the Mel-Scale band pass filter to mimic the human ears\n",
    "        - Cepstrum (Mel Frequency Cepstral Coefficients): In the final step, an inverse of the Fourier frame is carried out to bring them back to the time domain using the Discrete Cosine Transform which is formulated with:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "![ ](assets/math.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where, \n",
    "\n",
    "    x: original signal,\n",
    "    \n",
    "    y: result of Discrete Cosine Transformed signal, \n",
    "    \n",
    "    N: number of samples\n",
    "\n",
    "   - The modeling task stage: For modeling, a HMM model is made of data in the form of speech samples from a word (in the form of digital data). After segmentation, the parts of the MFCC matrix corresponding to each phoneme are used in the construction of the HMM model. For example, from the MFCC word \"mereka\", we get one model for \"m\", \"r\", \"k\", \"a\", and two models for \"e\". While practicing several words, it is possible to make the same phoneme model repeatedly. In this case, the phoneme model is named like \"e1\", \"e2\", \"e15\", and so on.\n",
    "   - HMM recognition system stage: At this stage, unknown speech must be identified as an Indonesian word (the case example is the word \"mereka\") using the phoneme model obtained at the speech reception stage. This introduction phase can be interpreted as a training process.\n",
    "\n",
    "3. Sound Pattern Matching Process \n",
    "\n",
    "Because the training is done at the phoneme level, the introduction of the HMM model must also be carried out at the same level. When doing training, the smallest phoneme length of all phonemes is stored in a parameter. At this matching stage, the unknown utterance is divided into smaller parts of the stored parameter value so that not every phoneme can be recognized without missing a single one. The most optimal minimum separation length found by an experiment is about half of the stored parameter values. After separating each part of the speech, the Viterbi HMM search was made with the feature vector extracted from that part. In general, speech recognition processes incoming voice signals and stores them in digital form. The results of the digitization process are then converted in the form of sound spectrum which will be analyzed by comparing it with the sound template in the system database. Previously, the input sound data was sorted and processed one by one based on the sequence. This selection is made so that the analysis process can be done in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](assets/speech-recognition.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to Text (STT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, STT works to change the input in the form of audio speech into text that has been stored in a database. Examples of the most common systems encountered are such as Siri which is on Apple or Cortana on Windows, or Google Voice which is on Android. The simple way of working from Speech to Text can be seen in the image below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](assets/tts-stt.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to use STT in python, the following required are:\n",
    "- Python with versions 2.6, 2.7 or 3.+\n",
    "- SpeechRecognition library\n",
    "How to install using `pip install SpeechRecognition` command on Anaconda Prompt.\n",
    "- PyAudio library\n",
    "How to install using `pip install PyAudio` command on Anaconda Prompt. If there is an error while installing this library, you can see the error resolution at https://stackoverflow.com/questions/53866104/pyaudio-failed-to-install-windows-10. Outside of the Windows OS you can see how to install it at https://pypi.org/project/SpeechRecognition/.\n",
    "- Google API Client Library for Python\n",
    "How to install using `pip install google-api-python-client` command on Anaconda Prompt\n",
    "- Set the language as needed to be recognized. In this exercise, we will use Indonesian.\n",
    "- Microphone as a speech input tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Example of Speech to Text Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyaudio\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tolong katakan sesuatu!\n",
      "Kamu bilang: algoritma data science indonesia\n",
      "\n",
      "Tolong katakan sesuatu!\n",
      "Kamu bilang: keluar\n",
      "\n",
      "Oke, sampai ketemu lagi bosku!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fafiliam\\.conda\\envs\\pyfaf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    r.pause_threshold = 1\n",
    "    # listen for 1 second to calibrate the energy threshold for ambient noise levels\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    while True:\n",
    "        print(\"Tolong katakan sesuatu!\")\n",
    "        audio = r.listen(source)\n",
    "        try:\n",
    "            get_text = r.recognize_google(audio, language = 'id-ID').lower()\n",
    "            print('Kamu bilang: ' + get_text + '\\n')\n",
    "            if(get_text == \"keluar\"):\n",
    "                print(\"Oke, sampai ketemu lagi bosku!\")\n",
    "                sys.exit()\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Aku tidak paham dengan yang kamu katakan!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to Speech(TTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text to Speech is a system that can convert text into audiovisual that can be heard. The text is converted into speech automatically through phonetization (arrangement of phonemes to form speech). A TTS system can say any word, because the vocabulary is unlimited. Examples of websites that provide TTS are www.naturalreaders.com, but Indonesian is not yet available.\n",
    "\n",
    "To be able to implement it in python, the GTTS library is needed. This library will create an mp3 file from text using Google TTS. The following steps and stages:\n",
    "- Libraries needed: gTTS, sys, os\n",
    "- To be able to play mp3 files, then the file directory must be available mpg123.exe file (already available in the internal training folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'PT. Algoritma Data Indonesia (Algoritma Data Science Education Center) resmi menandatangani kesepakatan dengan Ngee Ann Polytechnic, Singapore.'\n",
    "#testime = tes.strftime('%H:%M:%S')\n",
    "tts = gTTS(text, lang='id')\n",
    "tts.save('audio.mp3')\n",
    "os.system(\"mpg123 audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat ke dalam fungsi yang akan membaca text\n",
    "def speech_out(text):\n",
    "    tts = gTTS(text, lang='id')\n",
    "    tts.save('audio.mp3')\n",
    "    os.system(\"mpg123 audio.mp3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Application of JARVIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](assets/jarvis.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will create a simple JARVIS program using Speech Recognition. Just A Rather Very Intelligent System is a computer interface system that uses Tony Stark's natural language. In the code below given 2 ways to access / call an application (through speech recognition which will then be processed into a command). The first way, we will make the operating system to find its own program / application that will run based on the spoken voice conversion. The second way is by setting the application path which will be called based on the voice conversion spoken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyaudio\n",
    "import sys, os\n",
    "from gtts import gTTS\n",
    "import subprocess\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesin: Halo Tuanku, Apakah ada yang bisa dibantu?\n",
      "\n",
      "Mesin: Maaf, aku tidak dengar suaramu. Coba ulangi lagi!\n",
      "\n",
      "Kamu bilang: jam berapa\n",
      "\n",
      "Mesin: pukul 08:06:29\n",
      "\n",
      "Mesin: Apakah ada lagi yang bisa dibantu?\n",
      "\n",
      "Kamu bilang: tolong buka exo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the month\n",
    "bulan = [\"Januari\",\"Februari\",\"Maret\",\"April\",\"Mei\",\"Juni\",\"Juli\",\"Agustus\",\"September\",\"Oktober\",\"November\",\"Desember\"]\n",
    "\n",
    "def speech_out(text):\n",
    "    tts = gTTS(text, lang='id')\n",
    "    tts.save('audio.mp3')\n",
    "    os.system(\"mpg123 audio.mp3\")\n",
    "\n",
    "speech_out(\"halo Tuanku apakah ada yang bisa dibantu?\")\n",
    "print(\"Mesin: Halo Tuanku, Apakah ada yang bisa dibantu?\\n\")\n",
    "\n",
    "silent = 0\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    r.pause_threshold = 1\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    while True:\n",
    "        audio = r.listen(source)\n",
    "        try:\n",
    "            get_text = r.recognize_google(audio, language = 'id-ID').lower()\n",
    "            print('Kamu bilang: ' + get_text + '\\n')\n",
    "            \n",
    "            if(\"buka\" in get_text):\n",
    "                filename = get_text.split()[get_text.split().index(\"buka\")+1]\n",
    "                \n",
    "                if(os.system(\"start \"+filename+\".exe\")!=0):\n",
    "                    speech_out(\"Maaf,\"+ filename + \" tidak ditemukan\")\n",
    "                    print(\"Mesin: Maaf,\"+ filename + \" tidak ditemukan\\n\")\n",
    "                else:\n",
    "                    speech_out(\"Oke\")\n",
    "                    print(\"Mesin: Oke\\n\")\n",
    "            \n",
    "            if(\"tutup\" in get_text):\n",
    "                filename = get_text.split()[get_text.split().index(\"tutup\")+1]\n",
    "                \n",
    "                speech_out(\"Anda yakin ingin menutup \"+filename)\n",
    "                print(\"Mesin: Anda yakin ingin menutup \" + filename + \"?\\n\")\n",
    "                \n",
    "                if(os.system(\"taskkill /im \"+filename+\".exe /f\")!=0):\n",
    "                    speech_out(\"Maaf,\"+ filename + \" tidak ditemukan\")\n",
    "                    print(\"Mesin: Maaf,\"+ filename + \" tidak ditemukan\\n\")\n",
    "                else:\n",
    "                    speech_out(\"Oke\")\n",
    "                    print(\"Mesin: Oke\\n\")\n",
    "                    \n",
    "            if(\"jam\" in get_text and \"berapa\" in get_text):\n",
    "                speech_out(datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "                print(\"Mesin: pukul \"+ datetime.datetime.now().strftime(\"%H:%M:%S\") + \"\\n\")\n",
    "            \n",
    "            if(\"tanggal\" in get_text and \"berapa\" in get_text):\n",
    "                tanggal = str(datetime.datetime.now().date()).split(\"-\")\n",
    "                speech_out(tanggal[2] + \" \" + bulan[int(tanggal[1])] + \" \" +tanggal[0])\n",
    "                print(\"Mesin: tanggal \"+ tanggal[2] + \" \" + bulan[int(tanggal[1])] + \" \" +tanggal[0] + \"\\n\")\n",
    "            \n",
    "            if(get_text == \"keluar\" or get_text == \"tidak\" or get_text == \"nggak\"):\n",
    "                speech_out(\"Ok, sampai ketemu lagi!\")\n",
    "                print(\"Mesin: Ok, sampai ketemu lagi!\\n\")\n",
    "                sys.exit()\n",
    "                \n",
    "            speech_out(\"apakah ada lagi yang bisa dibantu?\")\n",
    "            print(\"Mesin: Apakah ada lagi yang bisa dibantu?\\n\")\n",
    "        except sr.UnknownValueError:\n",
    "            if(silent<3):\n",
    "                speech_out(\"Maaf, aku tidak dengar suaramu. Coba ulangi lagi!\")\n",
    "                print(\"Mesin: Maaf, aku tidak dengar suaramu. Coba ulangi lagi!\\n\")\n",
    "                silent += 1\n",
    "            else:\n",
    "                speech_out(\"Sepertinya kamu pergi, sampai ketemu lagi!\")\n",
    "                print(\"Mesin: Sepertinya kamu pergi, sampai ketemu lagi!\\n\")\n",
    "                sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the above methods, there are other ways, namely by defining the path / location of file.exe directly like the program code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuanku bilang :buka exo\n",
      "\n",
      "Tuanku bilang :kamu siapa\n",
      "\n",
      "Tuanku bilang :siapa kamu\n",
      "\n",
      "Nama saya Jarpis. Saya siap membantu tuanku dimanapun dan kapanpun\n",
      "Tuanku bilang :keluar\n",
      "\n",
      "Oke sampai ketemu lagi Tuanku. Semoga harimu menyenangkan!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fafiliam\\.conda\\envs\\pyfaf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "r=sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    r.pause_threshold=1\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    while True :\n",
    "        halo = \"Selamat datang Tuanku. Katakan sesuatu Tuanku\"\n",
    "        speech_out(halo)\n",
    "        audio = r.listen(source)\n",
    "        try :\n",
    "            get_text = r.recognize_google(audio, language = 'id-ID').lower()\n",
    "            print(\"Tuanku bilang :\"  +get_text+ \"\\n\")\n",
    "            speech_out(\"Tuanku bilang\" +get_text)\n",
    "            if(get_text == \"keluar\"):\n",
    "                print(\"Oke sampai ketemu lagi Tuanku. Semoga harimu menyenangkan!\")\n",
    "                sys.exit()\n",
    "            if(get_text == \"siapa kamu\"):\n",
    "                speech_out(\"Nama saya Jarpis. Saya siap membantu tuanku dimanapun dan kapanpun\")\n",
    "                print(\"Nama saya Jarpis. Saya siap membantu tuanku dimanapun dan kapanpun\")\n",
    "            elif(\"buka excel\" in get_text):\n",
    "                subprocess.call( 'C:\\Program Files (x86)\\Microsoft Office\\Office15\\EXCEL.EXE')\n",
    "                speech_out(\"Excel office siap digunakan Tuanku\")\n",
    "                print(\"Excel office siap digunakan Tuanku\")\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Aku ra mudeng sama yang kowe bilang!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strengths and Weaknesses of Speech Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speech Recognition has several advantages. This technology can speed up the transmission of information and feedback from that transmission. For example in command / voice commands. Only within an interval of about one or two seconds after we command voice commands, the computer has given feedback on our voice commands. In addition, another convenience is that the commands we give to the computer are done without hardware such as a mouse and keyboard or in other words we only use our voice to enter commands to the computer so that this greatly facilitates work.\n",
    "\n",
    "In addition to having advantages, speech recognition also has a weakness that is prone to interference or noise. This is caused by the process of sound signals that are still frequency based. When an information in a sound signal has as many frequency components as the frequency component of the noise, it will be difficult to separate the noise from the sound signal. In addition, the number of words that can be recognized is also limited. This is due to speech recognition works by finding similarities with the database owned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn by Building(LBB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for taking a part in the internal training session today. To upgrade your skills and understanding in following internal training, here a simple exercises that you can try on yor computer with the following conditions:\n",
    "1. Make a JARVIS (personal assistant) program that can call / open social media website pages:\n",
    "    - Facebook\n",
    "    - Twitter\n",
    "    - Algorithm website\n",
    "    - open RStudio\n",
    "   \n",
    "   ** For reference material to call the url, you can read the webbrowser package documentation at https://docs.python.org/2/library/webbrowser.html**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
